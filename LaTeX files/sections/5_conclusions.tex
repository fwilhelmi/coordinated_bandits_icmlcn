\section{Conclusions}
\label{sec:conclusions}

This paper explored the potential of coordinated MA-MAB to improve SR in MAPC-equipped Wi-Fi networks. Our findings demonstrate that coordinated MABs offer a significant advantage over the OBSS/PD SR operation and uncoordinated MABs. We studied different exploration-exploitation strategies and showed that explicit exploration ($\varepsilon$-greedy) grants control on the exploration but might not adapt properly to different situations, whereas implicit exploration (Thompson sampling) leads to higher instability but adapts well to various contexts and reward types, eventually leading to optimal policies. In addition, we studied different reward-sharing strategies and showed that metrics such as \texttt{AVG} and \texttt{PF} can drive agents to find global configurations that maximize overall performance. Meanwhile \texttt{MAX-MIN} is useful to maximize minimum performance, but fails to maximize overall performance in some situations. Future work will study the feasibility of the proposed solution through a detailed analysis of overheads and computations associated with the bandits' operation. 